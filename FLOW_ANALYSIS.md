# Treasure Hunt Model - Complete Flow Analysis

## Overview

This document traces the **exact execution flow** of the treasure hunt simulation, showing how agents spawn, update, communicate, and converge to find the treasure.

---

## ðŸš€ PHASE 1: INITIALIZATION (setup procedure)

### Step 1.1: Global Configuration
```netlogo
setup
  clear-all

  ; Set default values
  num-hunters = 5                    ; Number of agents
  communication-range = 2            ; Distance for agent communication
  confidence-threshold = 0.7         ; Minimum confidence to manifest treasure
  default-strategy = "mixed"         ; Exploration strategy
  llm-config-file = "demos/config"   ; LLM provider settings
  show-trails? = true                ; Visual trails enabled
  show-communications? = true        ; Communication effects enabled
```

**Key Default Values:**
- **5 agents** will be created
- Agents communicate when within **2 patches** of each other
- Treasure requires **0.7 (70%) confidence** to manifest
- Each agent gets a **random strategy** (methodical/random/wall-follower)

### Step 1.2: LLM Initialization
```netlogo
setup-llm
  llm:load-config "demos/config"
  ; Loads provider settings:
  ; - provider=ollama
  ; - model=llama3.2:latest
  ; - base_url=http://localhost:11434
  ; - temperature=0.7
  ; - max_tokens=500
```

**Result:** LLM extension ready to process agent conversations

### Step 1.3: World Creation
```netlogo
; Create 21x21 world
maze-width = 21
maze-height = 21
resize-world 0 20 0 20
```

**Result:** 441 patches (21Ã—21 grid)

### Step 1.4: Maze Generation
```netlogo
generate-maze
  1. Initialize all patches as walls (wall? = true)
  2. Start at patch (1, 1)
  3. Carve paths using recursive backtracking
  4. Create 3 meeting areas (open spaces in-radius 1)
  5. Add 5 random path connections for complexity
```

**Algorithm: Recursive Backtracking**
```
carve-maze-from(patch):
  1. Mark current patch as path (wall? = false, brown color)
  2. Get unvisited neighbors 2 steps away (N, S, E, W)
  3. For each random unvisited neighbor:
     a. Carve path between current and neighbor
     b. Recursively carve from neighbor
```

**Result:** Perfect maze with:
- ~50% walls, ~50% paths
- All paths connected
- 3 larger meeting areas
- Multiple dead ends and intersections

### Step 1.5: Agent Spawning
```netlogo
create-treasure-hunters 5 [
  setup-hunter
]
```

#### For Each Agent (0-4):

**Step 5a: Position**
```netlogo
move-to one-of patches with [not wall?]
; Random open patch in maze
```

**Step 5b: Knowledge Assignment**
```netlogo
knowledge-fragment = assign-knowledge-fragment
; Uses: who mod 6
; Agent 0: "The treasure is golden and round like the sun"
; Agent 1: "Look where two main paths cross each other"
; Agent 2: "The special place has coordinates that add up to exactly 15"
; Agent 3: "It only appears when all clues are combined"
; Agent 4: "The treasure glows and makes everyone happy"
; (If 6+ agents, clue 5 is: "Find the spot furthest from any wall")
```

**Step 5c: Initial State**
```netlogo
learned-facts = []                  ; Empty list (no learned knowledge yet)
current-goal = "explore"            ; Initial goal
confidence-level = 0                ; Zero confidence
last-communication = 0              ; Never communicated
memory-trail = []                   ; No visited patches yet
```

**Step 5d: Visual Properties**
```netlogo
shape = one-of ["person" "circle" "triangle" "square" "star"]
color = one-of [red blue green yellow magenta cyan orange pink]
size = 0.9                          ; Base size (will grow with confidence)
```

**Step 5e: Strategy Assignment**
```netlogo
; Since default-strategy = "mixed":
exploration-strategy = one-of ["methodical" "random" "wall-follower"]
; Each agent gets random strategy

; STRATEGIES:
; - "methodical": Prefers unexplored patches
; - "random": Moves randomly
; - "wall-follower": Right-hand rule
```

**Step 5f: Enable Trail**
```netlogo
pen-down                            ; Start drawing trail
pen-size = 2                        ; Thick line
; Agent's color shows in trail
```

**Console Output:**
```
Hunter 0 created with clue: "The treasure is golden and round like the sun"
  Strategy: methodical, Starting at (5, 7)
Hunter 1 created with clue: "Look where two main paths cross each other"
  Strategy: random, Starting at (12, 3)
Hunter 2 created with clue: "The special place has coordinates that add up to exactly 15"
  Strategy: wall-follower, Starting at (8, 15)
Hunter 3 created with clue: "It only appears when all clues are combined"
  Strategy: methodical, Starting at (17, 9)
Hunter 4 created with clue: "The treasure glows and makes everyone happy"
  Strategy: random, Starting at (3, 11)
```

### Initial State Summary

**World:**
- 441 patches (21Ã—21)
- ~220 path patches, ~220 wall patches
- 3 meeting areas
- Black borders

**Agents (5 total):**
```
Agent 0: {
  position: random_open_patch,
  knowledge: "golden and round like the sun",
  learned_facts: [],
  goal: "explore",
  confidence: 0.0,
  strategy: random_from["methodical","random","wall-follower"],
  color: random,
  shape: random,
  size: 0.9
}
... (same structure for agents 1-4 with different clues)
```

---

## ðŸ”„ PHASE 2: MAIN LOOP (go procedure)

Each tick executes:

```netlogo
to go
  if not any? treasure-hunters [ stop ]

  ask treasure-hunters [
    move-through-maze              ; Step 1: Movement
    detect-nearby-agents           ; Step 2: Communication detection
    analyze-current-situation      ; Step 3: Goal analysis (LLM)
    take-action-based-on-goal      ; Step 4: Goal execution
    update-exploration-memory      ; Step 5: Memory update
    update-agent-appearance        ; Step 6: Visual update
  ]

  update-visual-effects            ; Step 7: Environment effects
  check-treasure-conditions        ; Step 8: Check treasure status

  tick
end
```

### Step 1: Movement (move-through-maze)

Each agent moves based on their strategy:

#### Strategy A: "random"
```netlogo
possible-moves = patches within 1 step where wall? = false
move-to one-of possible-moves
```
**Result:** Random walk through maze

#### Strategy B: "methodical"
```netlogo
unexplored = patches within 1 step where (wall? = false AND explored? = false)
if any unexplored:
  move-to one-of unexplored        ; Prefer new areas
else:
  move-to one-of possible-moves    ; Fall back to random
```
**Result:** Systematic exploration, covers more ground

#### Strategy C: "wall-follower"
```netlogo
right 90
while (patch-ahead-1 is wall OR nobody):
  right 90
move-to patch-ahead-1
```
**Result:** Follows walls using right-hand rule, guaranteed to explore all connected areas

**After movement:**
```netlogo
ask patch-here [
  set explored? true
  set pcolor path-color + 0.5      ; Slightly brighter (visual feedback)
]
```

### Step 2: Communication Detection (detect-nearby-agents)

```netlogo
nearby-hunters = other treasure-hunters in-radius communication-range

; THRESHOLD CHECK: Must wait 5 ticks between communications
if any? nearby-hunters AND (ticks - last-communication) > 5:

  communication-partner = one-of nearby-hunters

  ; VISUAL EFFECTS:
  ask patch-here [
    set meeting-glow = 15
    set pcolor = yellow              ; Bright yellow glow
  ]

  ask patches in-radius 1.5 [
    if not wall? [
      set meeting-glow = 8
      set pcolor = yellow - 1        ; Spreading effect
    ]
  ]

  ; INITIATE CONVERSATION:
  communicate-with communication-partner

  last-communication = ticks
```

**Communication Conditions:**
1. At least one other agent within **2 patches** (communication-range)
2. At least **5 ticks** since last communication (cooldown)

**Example:**
```
Tick 47: Agent 0 at (8,7), Agent 2 at (9,8)
Distance = sqrt((9-8)Â² + (8-7)Â²) = sqrt(2) â‰ˆ 1.41 patches
1.41 < 2 â†’ WITHIN RANGE
Ticks since last: 47 - 0 = 47 > 5 â†’ READY TO COMMUNICATE
â†’ Communication initiated!
```

### Step 3: Knowledge Exchange (communicate-with)

This is where **LLM magic happens**!

```netlogo
to communicate-with [partner]
  ; PREPARE CONTEXT:
  my-info = "The treasure is golden and round like the sun. I have learned: []"
  partner-info = "Look where two main paths cross each other. They have learned: []"
  combined-info = "I know: [my-info]. My partner knows: [partner-info]"

  ; LLM SYNTHESIS:
  conversation-result = llm:chat(
    combined-info + ". What can we conclude about finding a treasure? Give me new insights."
  )

  ; EXAMPLE LLM RESPONSE:
  ; "Based on combining these clues, the treasure is likely a golden,
  ;  round object located at an intersection where paths cross."

  ; BOTH AGENTS LEARN:
  set learned-facts = lput conversation-result learned-facts
  ask partner [
    set learned-facts = lput conversation-result learned-facts
  ]

  ; CONFIDENCE INCREASE:
  confidence-level = confidence-level + 0.2
  if confidence-level > 1 [ set confidence-level = 1 ]
```

**Key Mechanism: Symmetric Learning**
- Both agents receive **identical insight** from LLM
- Both agents increase confidence by **+0.2 (20%)**
- Knowledge is **additive** (list grows)

**Console Output:**
```
=== AGENT INTERACTION at tick 47 ===
Hunter 0 meets Hunter 2
Location: (8, 7)
Sharing knowledge...
Consulting LLM for insights...
LLM Response: The treasure appears to be a golden, round object positioned
at a crossing point where the coordinate sum equals 15.
Hunter 0 learned: The treasure appears to be a golden, round object...
Hunter 2 also learned this insight
Confidence levels updated. Hunter 0: 0.20
================================
```

**State After First Meeting:**
```
Agent 0: {
  knowledge: "golden and round like the sun",
  learned_facts: ["The treasure appears to be a golden, round object positioned at a crossing point where the coordinate sum equals 15."],
  confidence: 0.2
}

Agent 2: {
  knowledge: "coordinates add up to exactly 15",
  learned_facts: ["The treasure appears to be a golden, round object positioned at a crossing point where the coordinate sum equals 15."],
  confidence: 0.2
}
```

### Step 4: Goal Analysis (analyze-current-situation)

**Trigger Conditions:**
```netlogo
if length(learned-facts) > 1 AND confidence-level > 0.3:
  ; Agent has enough knowledge and confidence to analyze
```

**LLM-Based Goal Selection:**
```netlogo
situation-summary = "My original clue: [knowledge-fragment].
                     What I've learned from others: [learned-facts].
                     I'm currently at coordinates (X, Y).
                     What should be my next goal?"

possible-goals = [
  "explore-more",            ; Keep searching
  "find-center",             ; Move toward maze center
  "find-crossing",           ; Seek path intersections
  "search-systematically",   ; Check current location
  "gather-more-info"         ; Find more agents
]

current-goal = llm:choose(situation-summary, possible-goals)
```

**Example:**
```
Tick 150: Agent 0 has learned from 3 different agents
learned-facts = [
  "golden round object at crossing where sum=15",
  "appears when all clues combined",
  "look for intersection furthest from walls"
]
confidence = 0.6

LLM receives:
"My original clue: The treasure is golden and round like the sun.
 What I've learned from others: [golden round object at crossing where sum=15,
 appears when all clues combined, look for intersection furthest from walls].
 I'm currently at coordinates (11, 7).
 What should be my next goal?"

LLM chooses: "find-crossing"
â†’ Agent 0 changes goal from "explore" to "find-crossing"
```

### Step 5: Goal Execution (take-action-based-on-goal)

Based on current goal:

#### Goal: "find-center"
```netlogo
center-patch = patch(10, 10)        ; maze-width/2, maze-height/2
face center-patch
; Agent orients toward center, next move-through-maze will go that direction
```

#### Goal: "find-crossing"
```netlogo
crossings = patches where (not wall? AND count(neighbors with [not wall?]) >= 3)
; Finds intersections (patches with 3+ open neighbors)

nearest-crossing = min-one-of crossings [distance myself]
face nearest-crossing
; Agent orients toward nearest intersection
```

#### Goal: "search-systematically"
```netlogo
check-treasure-location
; Evaluates current position (see Step 6)
```

#### Goal: "explore-more" or "gather-more-info"
```netlogo
; No action - continues normal exploration
```

### Step 6: Location Validation (check-treasure-location)

**Trigger:** Only when goal = "search-systematically"

```netlogo
if length(learned-facts) > 2:
  location-description = "I am at coordinates (X, Y).
                          The sum is (X+Y).
                          This location has N open neighbors.
                          Based on what I know: [learned-facts].
                          Could this be the treasure location?"

  location-assessment = llm:choose(location-description,
                                   ["yes-likely", "no-unlikely", "need-more-info"])

  if location-assessment = "yes-likely":
    location-matches? = true
```

**Example:**
```
Tick 487: Agent 3 at position (7, 8)
learned-facts = [5 synthesized insights including coordinate clue]
confidence = 0.8

LLM receives:
"I am at coordinates (7, 8).
 The sum is 15.
 This location has 4 open neighbors.
 Based on what I know: [treasure at intersection where coordinates sum to 15,
 golden round object, appears when all clues combined, ...]
 Could this be the treasure location?"

LLM responds: "yes-likely"

Agent checks: location-matches? = true AND confidence (0.8) > threshold (0.7)
â†’ ATTEMPT TREASURE MANIFESTATION
```

### Step 7: Treasure Manifestation (attempt-treasure-manifestation)

**Final Convergence Mechanism:**

```netlogo
if not treasure-discovered?:

  ; COLLECT ALL KNOWLEDGE:
  all-knowledge = []
  ask all treasure-hunters [
    all-knowledge += knowledge-fragment
    all-knowledge += learned-facts
  ]

  ; EXAMPLE all-knowledge:
  ; ["golden and round like the sun",
  ;  "paths cross each other",
  ;  "coordinates add up to 15",
  ;  "appears when all clues are combined",
  ;  "glows and makes everyone happy",
  ;  "synthesized insight 1...",
  ;  "synthesized insight 2...",
  ;  ...]

  combined-knowledge = reduce word all-knowledge

  ; FINAL LLM SYNTHESIS:
  treasure-description = llm:chat(
    "Based on all our clues: " + combined-knowledge +
    ". What exactly is the treasure and what does it look like?"
  )

  ; EXAMPLE LLM RESPONSE:
  ; "The treasure is a radiant golden orb, perfectly spherical like the sun,
  ;  that rests at the intersection of two main maze paths where the
  ;  coordinates sum to exactly 15. It glows with an inner light that brings
  ;  joy to all who behold it, manifesting only when all the scattered
  ;  knowledge fragments are united."

  if length(treasure-description) > 10:
    treasure-definition = treasure-description
    treasure-location = patch-here
    manifest-treasure
    treasure-discovered? = true
```

**Console Output:**
```
=== TREASURE MANIFESTATION ATTEMPT ===
Hunter 3 attempting to manifest treasure at (7, 8)
Combining all collective knowledge...
Asking LLM to describe the treasure...
LLM treasure description: The treasure is a radiant golden orb, perfectly
spherical like the sun, that rests at the intersection of two main maze
paths where the coordinates sum to exactly 15. It glows with an inner light
that brings joy to all who behold it, manifesting only when all the
scattered knowledge fragments are united.
TREASURE MANIFESTED! [description above]
================================
```

### Step 8: Visual Updates

**Agent Appearance (update-agent-appearance):**
```netlogo
size = 0.9 + (0.4 * confidence-level)
; confidence=0.0 â†’ size=0.9
; confidence=0.5 â†’ size=1.1
; confidence=1.0 â†’ size=1.3

if confidence-level > 0.5:
  color = base-color + 2            ; Brighter

if confidence-level > 0.8:
  ; Halo effect
  ask patches in-radius 1 [
    set pcolor = pcolor + 0.5
  ]
```

**Visual Effects (update-visual-effects):**
```netlogo
; Meeting glow decay
ask patches with [meeting-glow > 0] [
  meeting-glow = meeting-glow - 1
  if meeting-glow = 0:
    pcolor = path-color              ; Return to normal
]

; Treasure animation
if treasure-discovered?:
  ask treasures [
    glow-phase += 0.3
    color = yellow + 2 + 2*sin(glow-phase * 180)    ; Pulsating
    size = 1.2 + 0.3*sin(glow-phase * 90)            ; Breathing effect

    ; Radiate light
    ask patches in-radius 2 [
      glow-intensity = (3 - distance) / 3
      pcolor = yellow + glow-intensity * 2
    ]

    ; Random sparkles
    if random(10) < 3:
      ask one-of patches in-radius 1.5 [
        pcolor = white
        meeting-glow = 3
      ]
  ]
```

---

## ðŸ“Š CONVERGENCE MECHANISM

### How Agents Converge to Find Treasure

The simulation uses **multi-level convergence**:

#### Level 1: Spatial Convergence (Movement)
```
Random exploration â†’ LLM identifies patterns â†’ Goal selection â†’
Directed movement toward likely locations
```

**Timeline:**
- **Ticks 0-100:** Random wandering, broad coverage
- **Ticks 100-300:** Some agents develop "find-crossing" goal
- **Ticks 300+:** Multiple agents converge on intersection areas

#### Level 2: Knowledge Convergence (Communication)
```
Individual clues â†’ Pairwise synthesis â†’ Network propagation â†’
Collective understanding
```

**Mechanism: Epidemic Spread**
```
Tick 50:  Agent 0 â† â†’ Agent 2
          Both learn insight A

Tick 150: Agent 0 â† â†’ Agent 4
          Agent 4 learns insight A
          Agent 0 learns new insight B
          Both gain insight B

Tick 200: Agent 4 â† â†’ Agent 1
          Agent 1 learns insights A + B
          Agent 4 learns new insight C
          Both gain insight C

Result: Exponential knowledge propagation
```

**Mathematical Model:**
```
Knowledge(agent, t) = original_clue + Î£(synthesized_insights_from_meetings)
Confidence(agent, t) = min(1.0, 0.2 * number_of_meetings)

Global_Knowledge(t) = âˆª Knowledge(agent_i, t) for all agents
Convergence occurs when:
  âˆƒ agent where:
    - Confidence(agent) > threshold (0.7)
    - Location(agent) matches clues
    - Global_Knowledge contains sufficient info
```

#### Level 3: Confidence Convergence (Certainty Building)
```
0 meetings â†’ confidence = 0.0
1 meeting  â†’ confidence = 0.2
2 meetings â†’ confidence = 0.4
3 meetings â†’ confidence = 0.6
4 meetings â†’ confidence = 0.8  â† ABOVE THRESHOLD (0.7)
5 meetings â†’ confidence = 1.0  (capped)
```

**Threshold Gate:**
```netlogo
if confidence > 0.7 AND location-matches? AND sufficient-knowledge?:
  â†’ MANIFEST TREASURE
else:
  â†’ CONTINUE SEARCHING
```

#### Level 4: Location Convergence (Spatial Reasoning)

**Clue Analysis:**
```
Clue: "coordinates add up to exactly 15"
â†’ Valid locations: (0,15), (1,14), (2,13), ..., (7,8), (8,7), ..., (15,0)

Clue: "where two main paths cross"
â†’ Must have count(neighbors with [not wall?]) >= 3

Clue: "furthest from any wall"
â†’ Prefer patches with max distance to nearest wall

Combined: Intersection at (X,Y) where X+Y=15, far from walls
```

**LLM Spatial Reasoning:**
```netlogo
llm:choose("I am at (7, 8). Sum is 15. This has 4 open neighbors.
            Based on clues about crossing paths and sum=15, is this likely?",
           ["yes-likely", "no-unlikely", "need-more-info"])
â†’ "yes-likely"
```

### Typical Timeline

| Ticks | Phase | Knowledge Spread | Avg Confidence | Agent Behavior |
|-------|-------|------------------|----------------|----------------|
| 0-100 | Exploration | 0-5 insights | 0.0-0.2 | Random wandering |
| 100-300 | First Contacts | 5-20 insights | 0.2-0.4 | Some goal changes |
| 300-600 | Knowledge Explosion | 20-50 insights | 0.4-0.7 | Directed search |
| 600-1000 | Convergence | 50+ insights | 0.7-1.0 | Systematic checking |
| 1000+ | Discovery | All clues combined | 0.8-1.0 | Treasure manifests |

---

## ðŸ”‘ KEY CONVERGENCE FACTORS

### Factor 1: Communication Range
```
Range = 1: Rare meetings, slow convergence (1500+ ticks)
Range = 2: Balanced (500-1000 ticks) â† DEFAULT
Range = 5: Frequent meetings, fast convergence (200-500 ticks)
```

### Factor 2: Agent Count
```
2 agents: Minimal meetings, very slow (2000+ ticks)
5 agents: Balanced network effects (500-1000 ticks) â† DEFAULT
10 agents: Dense network, fast (300-600 ticks)
```

### Factor 3: Confidence Threshold
```
Threshold = 0.5: Quick but uncertain (300-500 ticks)
Threshold = 0.7: Balanced certainty (500-1000 ticks) â† DEFAULT
Threshold = 0.9: Very thorough (1000-1500 ticks)
```

### Factor 4: LLM Quality
```
Fast models (llama3.2): Decent reasoning, fast responses
Mid models (GPT-4o-mini): Good reasoning, moderate speed â† RECOMMENDED
Advanced models (Claude-3.5-Sonnet): Excellent reasoning, slower
```

---

## ðŸŽ¯ SUMMARY: The Complete Flow

```
INITIALIZATION:
â”œâ”€ Create 21Ã—21 maze with recursive backtracking
â”œâ”€ Spawn 5 agents at random positions
â”œâ”€ Assign each agent 1 unique clue (6 total clues, modulo for extras)
â”œâ”€ Set confidence=0, learned-facts=[], goal="explore"
â””â”€ Assign random strategy (methodical/random/wall-follower)

MAIN LOOP (each tick):
â”œâ”€ MOVEMENT: Agents move based on strategy
â”‚   â”œâ”€ Random: one-of adjacent open patches
â”‚   â”œâ”€ Methodical: prefer unexplored patches
â”‚   â””â”€ Wall-follower: right-hand rule
â”‚
â”œâ”€ COMMUNICATION: If agent within range + cooldown expired
â”‚   â”œâ”€ Prepare: my-clue + learned-facts + partner-clue + partner-learned
â”‚   â”œâ”€ LLM Synthesis: "What can we conclude about the treasure?"
â”‚   â”œâ”€ Both Learn: append result to learned-facts
â”‚   â””â”€ Both Gain: confidence += 0.2
â”‚
â”œâ”€ GOAL ANALYSIS: If learned-facts>1 AND confidence>0.3
â”‚   â”œâ”€ LLM Choose: Pick best goal from 5 options
â”‚   â””â”€ Update: current-goal
â”‚
â”œâ”€ GOAL EXECUTION: Based on current-goal
â”‚   â”œâ”€ find-center: face (10,10)
â”‚   â”œâ”€ find-crossing: face nearest intersection
â”‚   â””â”€ search-systematically: check-treasure-location
â”‚
â””â”€ LOCATION CHECK: If goal=search AND learned-facts>2
    â”œâ”€ LLM Assess: "Is (X,Y) likely the treasure location?"
    â”œâ”€ If yes-likely AND confidence>0.7:
    â”‚   â”œâ”€ Collect: ALL knowledge from ALL agents
    â”‚   â”œâ”€ LLM Describe: "What exactly is the treasure?"
    â”‚   â””â”€ MANIFEST: Create treasure, treasure-discovered?=true
    â””â”€ Continue searching

CONVERGENCE:
â”œâ”€ Knowledge spreads exponentially through meetings
â”œâ”€ Confidence builds linearly with meetings
â”œâ”€ Goals shift from explore â†’ find-crossing â†’ search-systematically
â”œâ”€ Multiple agents check promising locations
â””â”€ First agent with sufficient knowledge + confidence + correct location succeeds
```

---

## ðŸ’¡ Why This Works

**Emergent Intelligence Properties:**

1. **No Central Coordination:** Each agent acts independently
2. **Local Interactions:** Agents only see nearby agents (range=2)
3. **Knowledge Synthesis:** LLM creates insights beyond simple combination
4. **Distributed Search:** Multiple agents explore different areas
5. **Adaptive Behavior:** Goals change based on accumulated knowledge
6. **Threshold Convergence:** System naturally finds solution when conditions met

**The "Aha!" Moment:**

The treasure manifests when:
- **Spatial:** Agent at correct location (coordinates sum to 15, intersection)
- **Epistemic:** Agent has high confidence (0.7+, meaning 4+ meetings)
- **Collective:** All clues have been shared and synthesized
- **Temporal:** Sufficient time has passed for knowledge to propagate

This mirrors real-world collaborative problem-solving: **no individual knows the answer, but the group collectively discovers it through communication and reasoning**.

---

## ðŸ”¬ Experimental Validation

You can verify this flow by:

1. **Watch the console output** - See exact LLM conversations
2. **Monitor the plots** - Confidence and knowledge graphs show convergence
3. **Observe agent size** - Larger agents have more confidence
4. **Track meetings** - Yellow glow shows knowledge transfer
5. **Check coordinates** - Treasure appears at intersection where X+Y=15

**Try modifying:**
- `communication-range` â†’ Changes meeting frequency
- `confidence-threshold` â†’ Changes certainty required
- `num-hunters` â†’ Changes network density
- Knowledge fragments in code â†’ Creates new puzzles
